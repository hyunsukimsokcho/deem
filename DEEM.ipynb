{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "import os\n",
    "import requests\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "import math\n",
    "import random\n",
    "import copy \n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from Component.duplicator import Duplicator\n",
    "from Component.reweighing import Reweighing\n",
    "from Component.preprocessing import Preprocessing\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset and Duplicating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = \"AdultCensus\"\n",
    "feature = \"@sex\"\n",
    "duplicator = Duplicator(category=dataset)\n",
    "\n",
    "if dataset == \"AdultCensus\":\n",
    "    p_group = \"Male\"\n",
    "    up_group = \"Female\"\n",
    "elif dataset == \"GermanBank\":\n",
    "    p_group = \"Male\"\n",
    "    up_group = \"Female\"\n",
    "elif dataset == \"Compas\":\n",
    "    p_group = \"Female\"\n",
    "    up_group = \"Male\"\n",
    "\n",
    "raw_train_data, raw_test_data = duplicator.train_data, duplicator.test_data\n",
    "duplicator.add_raw_duplicate(4)\n",
    "duplicate_train_data, test_data = duplicator.train_data, duplicator.test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessing = Preprocessing(dataset=dataset)\n",
    "raw_train_x, raw_train_y, raw_test_x, raw_test_y = data_preprocessing.transform(train_data=raw_train_data, test_data=raw_test_data)\n",
    "duplicate_train_x, duplicate_train_y, duplicate_test_x, duplicate_test_y = data_preprocessing.transform(train_data=duplicate_train_data, test_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(penalty='l1')\n",
    "model.fit(raw_train_x, raw_train_y)\n",
    "print(\"Training acc : %0.3f\" % model.score(raw_train_x, raw_train_y))\n",
    "print(\"Test acc : %0.3f\" % model.score(raw_test_x, raw_test_y))\n",
    "\n",
    "model = LogisticRegression(penalty='l1')\n",
    "model.fit(duplicate_train_x, duplicate_train_y)\n",
    "print(\"Training acc : %0.3f\" % model.score(duplicate_train_x, duplicate_train_y))\n",
    "print(\"Test acc : %0.3f\" % model.score(duplicate_test_x, duplicate_test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Poisoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poisoned = Poisoning(data=duplicate_train_x, label=duplicate_train_y)\n",
    "poisoned.add_adversarial(percentage=10)\n",
    "poisoned_data, poisoned_label = poisoned.return_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure accuracy and demographic parity on original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(penalty='l1')\n",
    "model.fit(duplicate_train_x, duplicate_train_y)\n",
    "print(\"Training acc : %0.3f\" % model.score(duplicate_train_x, duplicate_train_y))\n",
    "print(\"Test acc : %0.3f\" % model.score(duplicate_test_x, duplicate_test_y))\n",
    "\n",
    "reweighing = Reweighing(duplicate_train_x, duplicate_train_y, feature, p_group, up_group)\n",
    "original_dp = reweighing.fairness_measure(model)\n",
    "print(\"Demographic parity : %0.3f\" % original_dp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure accuracy and demographic parity on poisoned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_result(x_train, y_train, x_test, y_test, fair=False, weight=None):\n",
    "    mitigated_model = LogisticRegression(penalty='l1')\n",
    "    reweighing.change_data(x_train, y_train)\n",
    "    \n",
    "    if fair:\n",
    "        sample_weight = reweighing.calculate_weight()\n",
    "    elif weight is not None:\n",
    "        sample_weight = weight\n",
    "    else:\n",
    "        sample_weight = np.ones(len(x_train))\n",
    "    mitigated_model.fit(x_train, y_train, sample_weight=sample_weight)\n",
    "    print(\"Training acc : %0.3f\" % model.score(x_train, y_train))\n",
    "    print(\"Test acc : %0.3f\" % model.score(x_test, y_test))\n",
    "\n",
    "    demo_parity = reweighing.fairnesss_measure(model)\n",
    "    print(\"Demographic parity : %0.3f\" % demo_parity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case 1 : Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data, cleaned_label = cleaning(poisoned_data, poisoned_label)\n",
    "show_result(cleaned_data, cleaned_label, duplicate_test_x, duplicate_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case 2 : Data Sanitization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanitized_data, sanitized_label = sanitization(poisoned_data, poisoned_label)\n",
    "show_result(sanitized_data, sanitized_label, duplicate_test_x, duplicate_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case 3 : Unfiarness Mitigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_result(poisoned_data, poisoned_label, duplicate_test_x, duplicate_test_y, True):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case 4 : Data Cleaning -> Data Sanitization -> Unfairness Mitigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data, cleaned_label = cleaning(poisoned_data, poisoned_label)\n",
    "sanitized_data, sanitized_label = sanitization(cleaned_data, cleaned_label)\n",
    "show_result(sanitized_data, sanitized_label, duplicate_test_x, duplicate_test_y, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case 5 : Unfairness Mitigation -> Data Sanitization -> Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reweighing.change_data(poisoned_data, poisoned_label)\n",
    "sample_weight = reweighing.calculate_weight()\n",
    "\n",
    "cleaned_data, cleaned_label = cleaning(poisoned_data, poisoned_label)\n",
    "sanitized_data, sanitized_label = sanitization(cleaned_data, cleaned_label)\n",
    "\n",
    "show_result(sanitized_data, sanitized_label, x_test, y_test, weight=sample_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case 6 : MLClean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(data, train):\n",
    "    data_copy = data.copy()\n",
    "    data_copy[\"Target\"] = data_copy[\"Target\"].apply(lambda x:0 if (x=='<=50K' or x=='<=50K.') else 1)\n",
    "    x_data = data_copy.drop('Target', axis =1)\n",
    "    y_data = data_copy['Target']\n",
    "\n",
    "    num_data = x_data.select_dtypes(include=\"int\")\n",
    "    cat_data = x_data.select_dtypes(include='object')\n",
    "\n",
    "    if train==1:\n",
    "        num_data = pd.DataFrame(scalar.fit_transform(num_data), columns=num_data.columns)\n",
    "    else:\n",
    "        num_data = pd.DataFrame(scalar.transform(num_data), columns=num_data.columns)\n",
    "    cat_data = pd.get_dummies(cat_data)\n",
    "\n",
    "    x_data = pd.concat([num_data, cat_data], axis=1)\n",
    "    return x_data, y_data\n",
    "\n",
    "names = [\n",
    "        \"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Marital Status\",\n",
    "        \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\", \"Capital Loss\",\n",
    "        \"Hours per week\", \"Country\", \"Target\"]\n",
    "\n",
    "train_data = pd.read_csv('Dataset/AdultCensus/train.data', names=names, \n",
    "             sep=' *, *', na_values='?')\n",
    "test_data  = pd.read_csv('Dataset/AdultCensus/test.data', names=names, \n",
    "             sep=' *, *', skiprows=1, na_values='?')\n",
    "\n",
    "train_data.drop(['fnlwgt', 'Education'], axis=1, inplace=True)\n",
    "test_data.drop(['fnlwgt', 'Education'], axis=1, inplace=True)\n",
    "train_data = train_data.dropna().reset_index(drop=True)\n",
    "test_data = test_data.dropna().reset_index(drop=True)\n",
    "\n",
    "scalar = StandardScaler()\n",
    "x_train, y_train = data_preprocessing(train_data, 1)\n",
    "x_test, y_test = data_preprocessing(test_data, 0)\n",
    "\n",
    "missing_cols = set(x_train.columns) - set(x_test.columns)\n",
    "for column in missing_cols:\n",
    "    print(column)\n",
    "    x_test[column] = 0\n",
    "x_test = x_test[x_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()\n",
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=0, penalty='l1')\n",
    "#model = LinearSVC(penalty='l1', dual=False, loss='l2')\n",
    "model.fit(x_train, y_train)\n",
    "print(model.score(x_train, y_train))\n",
    "print(model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index1 = y_train.index[y_train.values==1].tolist()\n",
    "print(len(test_index1))\n",
    "test_index2 = y_train.index[y_train.values==0].tolist()\n",
    "print(len(test_index2))\n",
    "\n",
    "test_index3 = y_test.index[y_test.values==1].tolist()\n",
    "print(len(test_index3))\n",
    "test_index4 = y_test.index[y_test.values==0].tolist()\n",
    "print(len(test_index4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_poisoing(data):\n",
    "    return data\n",
    "\n",
    "def data_duplicate(data):\n",
    "    return data\n",
    "\n",
    "def cleaning(data):\n",
    "    return data\n",
    "\n",
    "def sanitization(data):\n",
    "    return data\n",
    "\n",
    "def reweighing(data, label, feature, p_group, up_group):\n",
    "    size = len(data)\n",
    "    p_feature = feature+\"_\"+p_group\n",
    "    up_feature = feature+\"_\"+up_group\n",
    "\n",
    "    up_index = data.index[data[up_feature]==1].tolist()\n",
    "    p_index = data.index[data[p_feature]==1].tolist()\n",
    "    f_index = label.index[label.values==1].tolist()\n",
    "    uf_index = label.index[label.values==0].tolist()\n",
    "\n",
    "    f_up_index = list(set(f_index)&set(up_index))\n",
    "    f_p_index = list(set(f_index)&set(p_index))\n",
    "    uf_up_index = list(set(uf_index)&set(up_index))\n",
    "    uf_p_index = list(set(uf_index)&set(p_index))\n",
    "\n",
    "    weight_f_up = len(f_index) * len(up_index) / (size * len(f_up_index))\n",
    "    weight_f_p = len(f_index) * len(p_index) / (size * len(f_p_index))\n",
    "    weight_uf_up = len(uf_index) * len(up_index) / (size * len(uf_up_index))\n",
    "    weight_uf_p = len(uf_index) * len(p_index) / (size * len(uf_p_index))\n",
    "\n",
    "    weight = np.zeros(size)\n",
    "    weight[f_up_index] = weight_f_up\n",
    "    weight[f_p_index] = weight_f_p\n",
    "    weight[uf_up_index] = weight_uf_up\n",
    "    weight[uf_p_index] = weight_uf_p\n",
    "    return weight\n",
    "\n",
    "def fairness_measure(data, label, model, feature, p_group, up_group):\n",
    "    p_feature = feature+\"_\"+p_group\n",
    "    up_feature = feature+\"_\"+up_group\n",
    "    prediction = model.predict(data)\n",
    "    \n",
    "    p_index = data.index[data[p_feature]==1].tolist()\n",
    "    up_index = data.index[data[up_feature]==1].tolist()\n",
    "    \n",
    "    p_pred = prediction[p_index]\n",
    "    up_pred = prediction[up_index]\n",
    "    p_ratio = np.sum(p_pred)/len(p_pred)\n",
    "    up_ratio = np.sum(up_pred)/len(up_pred)\n",
    "    print(p_ratio, up_ratio, p_ratio/up_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fairness_measure(x_train, y_train, model, \"Sex\", \"Female\", \"Male\" )\n",
    "sample_weight = reweighing(x_train, y_train, \"Sex\", \"Female\", \"Male\")\n",
    "\n",
    "mitigated_model = LogisticRegression(random_state=0, penalty='l1')\n",
    "mitigated_model.fit(x_train, y_train, sample_weight=sample_weight)\n",
    "print(mitigated_model.score(x_train, y_train))\n",
    "print(mitigated_model.score(x_test, y_test))\n",
    "\n",
    "fairness_measure(x_train, y_train, mitigated_model, \"Sex\", \"Female\", \"Male\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
